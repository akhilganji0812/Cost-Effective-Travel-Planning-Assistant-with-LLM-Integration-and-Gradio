{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc13300-814c-4619-af2c-bd9666075283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'os' module to interact with the operating system (e.g., environment variables, file paths)\n",
    "import os  \n",
    "\n",
    "# Importing the 'load_dotenv' function from 'dotenv' package to load environment variables from a .env file\n",
    "from dotenv import load_dotenv  \n",
    "\n",
    "# Importing the 'OpenAI' class from the 'openai' library to interact with OpenAI API services\n",
    "from openai import OpenAI  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83660db-92b5-4b02-b1cd-b56a375a643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all environment variables from the .env file into the system environment\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the OpenAI API key stored in the environment variable 'OPENAI_API_KEY'\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c7f3d8e-fb34-4697-8246-92e18b64007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the OpenAI client to interact with the API\n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d68ef4fa-a13c-42b9-911c-74b85a58370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a multi-line string (triple quotes) that serves as the system/user prompt for the LLM\n",
    "prompt = '''You are a Cost-Effective Travel Assistant.  \n",
    "\n",
    "Your role is to plan trips for users based on their inputs: trip duration, budget, and group size.  \n",
    "\n",
    "You must optimize **accommodation, transportation, and sightseeing recommendations** so that the entire plan stays within budget.  \n",
    "\n",
    "Guidelines:\n",
    "- Always stay funny, witty, and conversational (like a travel buddy with a sense of humor).  \n",
    "- Be practical but also entertainingâ€”make the user smile while giving useful advice.  \n",
    "- Suggest cost-saving hacks (e.g., public transport, budget hotels, local food stalls).  \n",
    "- Provide a structured trip plan (Day-wise if needed).  \n",
    "- Ensure recommendations are realistic and feasible within the budget.  \n",
    "- Add quirky remarks, emojis, or jokes to keep the tone engaging.  \n",
    "- And also make sure to tell them if the budget is not enough, and suggest how much extra money they need to add to make the trip possible, otherwise inform them no trip can be planned.  \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a8c2ae2-0e02-4d1c-97a2-036f4dab433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function 'gpt' that takes two inputs:\n",
    "# msg -> the new user message\n",
    "# his -> the conversation history (list of messages)\n",
    "def gpt(msg, his):\n",
    "    # Construct the full message list:\n",
    "    # Start with the system prompt, then add conversation history, then the new user message\n",
    "    message = [{'role': 'system', 'content': prompt}] + his + [{'role': 'user', 'content': msg}]\n",
    "    \n",
    "    # Call the OpenAI Chat API with streaming enabled\n",
    "    result = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',  # The model being used\n",
    "        messages=message,     # The constructed conversation\n",
    "        stream=True           # Enable streaming response\n",
    "    )\n",
    "    \n",
    "    # Initialize an empty string to collect the streamed response\n",
    "    p = ''\n",
    "    \n",
    "    # Iterate through the streamed chunks of response\n",
    "    for i in result:\n",
    "        # Append new content if available (avoid None values with 'or \"\"')\n",
    "        p += i.choices[0].delta.content or ''\n",
    "        \n",
    "        # Yield the progressively built response (generator style)\n",
    "        yield p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17545355-db7c-4d4e-a168-57b6f5495ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Gradio library for creating a simple web-based user interface\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db7c0664-0b76-427e-a608-e3673f7ba61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* Running on public URL: https://1e195526e6b1c13829.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1e195526e6b1c13829.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local URL: http://127.0.0.1:7867/\n",
      "Share URL: https://1e195526e6b1c13829.gradio.live\n"
     ]
    }
   ],
   "source": [
    "# Create a Gradio ChatInterface where 'gpt' function handles the conversation\n",
    "# 'type=\"messages\"' ensures the history is passed in the format expected by the gpt() function\n",
    "gui = gr.ChatInterface(fn=gpt, type='messages')\n",
    "\n",
    "# Launch the Gradio app with sharing enabled (generates both local and public URLs)\n",
    "app, local_url, share_url = gui.launch(share=True)\n",
    "\n",
    "# Print the local URL (accessible only on the same machine)\n",
    "print(\"Local URL:\", local_url)\n",
    "\n",
    "# Print the shareable public URL (accessible from anywhere)\n",
    "print(\"Share URL:\", share_url)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
